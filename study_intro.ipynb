{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc02f470-c593-4fda-96f9-0270e1edabf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_18692\\4195508914.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cbc812f-4968-4acb-8e73-848fc62c0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_batches_from_folder(folder_path, batch_size):\n",
    "    # Get a list of all files in the folder\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out non-image files (you can customize this based on your file extensions)\n",
    "    image_files = [file for file in all_files if file.lower().endswith(('.jpg'))]\n",
    " \n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # Split the triplicated image files into batches\n",
    "    batches = [image_files[i:i + batch_size] for i in \n",
    "               range(0, len(image_files), batch_size)]\n",
    "    \n",
    "    # Generate full paths for each batch\n",
    "    batch_paths = [[os.path.join(folder_path, image) for image in batch] for batch in batches]\n",
    "    batch_paths_triple = [batch for batch in batch_paths for _ in range(3)]\n",
    "    \n",
    "    return batch_paths_triple\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'sample_images'\n",
    "batch_size = 5\n",
    "result = generate_batches_from_folder(folder_path, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58b1b15-5fe3-4674-8c12-501e9b2fefef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_images\\\\school boy face (3).jpg',\n",
       " 'sample_images\\\\school boy face (5).jpg',\n",
       " 'sample_images\\\\school girl face (3).jpg',\n",
       " 'sample_images\\\\school girl face (1).jpg',\n",
       " 'sample_images\\\\school boy face.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f299f9e-28b1-4927-b5a0-7eac152ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_user_to_pics(username):\n",
    "    df_users = pd.DataFrame()\n",
    "    df_users['pictures'] = get_pictures()\n",
    "    df_users['username'] = username\n",
    "    df_users.to_csv(f\"ratings_{username}.csv\", index=False)\n",
    "    return True\n",
    "\n",
    "def get_pictures():\n",
    "    return generate_batches_from_folder('sample_images', 5)[0]\n",
    "\n",
    "nxt_page = False\n",
    "\n",
    "def next_page(username):\n",
    "    global nxt_page\n",
    "    if (len(username)>0) & (len(username)<12):\n",
    "        nxt_page = True\n",
    "        return gr.Button(interactive=True, value=\"Continue\")\n",
    "    return gr.Button(interactive=False, value=\"Continue\")\n",
    "    \n",
    "    \n",
    "\n",
    "with gr.Blocks() as introduction:\n",
    "    with gr.Tab(\"pg1\"):\n",
    "        gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Introduction\n",
    "        Hello and welcome to our study! Our goal is to create a dataset of realistic images of faces \n",
    "        generated by artificial intelligence. Most AI-generated images contain at least small mistakes.\n",
    "        We want to assign a category and a level of mistake to each image. In this study you will be presented \n",
    "        with different images with varying degrees of mistakes. For some mistakes you may need to zoom in on \n",
    "        the picture. There are five different mistake categories:\n",
    "        * Alignment Problem\n",
    "        * Incorrect Proportions\n",
    "        * Number of features\n",
    "        * Wrong Aspects\n",
    "        * Unrealistic\n",
    "        \n",
    "        Enter a username and press continue to see some examples of images and their categories.\n",
    "        \"\"\")\n",
    "        username = gr.Textbox(placeholder=\"Username\", label=\"Enter any username\", max_lines=1)\n",
    "        nxt_page = gr.Button(interactive=False, value=\"Continue\")\n",
    "        username.change(next_page, username, nxt_page)\n",
    "        nxt_page.click(link_user_to_pics, inputs=username)\n",
    "        \n",
    "    with gr.Tab(\"pg2\", interactive=True):\n",
    "        gr.Button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f702eee-fcee-4e9f-9a86-99ed4fe0a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo = gr.TabbedInterface([introduction], [\"Introduction\"])\n",
    "\n",
    "# demo.launch()\n",
    "introduction.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27f63d3-572f-4385-ba80-1407e42d6ffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Interface.__init__() missing 3 required positional arguments: 'fn', 'inputs', and 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m demo:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mTab(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLion\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m         gr\u001b[38;5;241m.\u001b[39mButton(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew Lion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Interface.__init__() missing 3 required positional arguments: 'fn', 'inputs', and 'outputs'"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Lion\"):\n",
    "        gr.Button(\"New Lion\")\n",
    "    with gr.Tab(\"Tiger\", interactive=False):\n",
    "        b = gr.Button(\"New Tiger\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc1b1dc-66cc-448d-897f-7d2a541e3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Tab(\"test\") as est:\n",
    "    gr.Button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e252da-d4d3-42f0-b73c-12a5def1e696",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tab' object has no attribute 'launch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tab' object has no attribute 'launch'"
     ]
    }
   ],
   "source": [
    "est.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9f39d6-6e52-44ce-a41f-a9c5bd4196f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\Documents\\projectReinforcementLearning\\venv\\Lib\\site-packages\\gradio\\blocks.py:532: UserWarning: Theme should be a class loaded from gradio.themes\n",
      "  warnings.warn(\"Theme should be a class loaded from gradio.themes\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Blocks' object has no attribute 'exited'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m layout \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mBlocks([image_block, zoomable_image_block])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Launch the Gradio Blocks interface\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mlayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\Documents\\projectReinforcementLearning\\venv\\Lib\\site-packages\\gradio\\blocks.py:1835\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, _frontend)\u001b[0m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_running_in_reload_thread:\n\u001b[0;32m   1832\u001b[0m     \u001b[38;5;66;03m# We have already launched the demo\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 1835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexited\u001b[49m:\n\u001b[0;32m   1836\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m()\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1839\u001b[0m     auth\n\u001b[0;32m   1840\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(auth)\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(auth[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(auth[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m   1843\u001b[0m ):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Blocks' object has no attribute 'exited'"
     ]
    }
   ],
   "source": [
    "image = \"images/a realistic face (1).jpg\"\n",
    "# Custom HTML block for the zoomable image\n",
    "zoomable_image_block = gr.Blocks(\n",
    "    [\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style='position:relative;width:100%;height:100%;'>\n",
    "            <img id='zoomable-image' src='' style='width:100%;height:auto;'>\n",
    "            <div id='zoom-overlay' style='position:absolute;top:0;left:0;width:100%;height:100%;background-color:black;opacity:0;pointer-events:none;transition:opacity 0.3s;'></div>\n",
    "        </div>\n",
    "        <script>\n",
    "            var image = document.getElementById('zoomable-image');\n",
    "            var overlay = document.getElementById('zoom-overlay');\n",
    "            image.addEventListener('mouseenter', function() {\n",
    "                overlay.style.opacity = '0.5';\n",
    "            });\n",
    "            image.addEventListener('mouseleave', function() {\n",
    "                overlay.style.opacity = '0';\n",
    "            });\n",
    "            image.addEventListener('mousemove', function(e) {\n",
    "                var rect = image.getBoundingClientRect();\n",
    "                var x = (e.clientX - rect.left) / rect.width * 100;\n",
    "                var y = (e.clientY - rect.top) / rect.height * 100;\n",
    "                overlay.style.backgroundPosition = x + '% ' + y + '%';\n",
    "            });\n",
    "        </script>\n",
    "        \"\"\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "image_block = gr.Blocks(\n",
    "    [\n",
    "        gr.Image(image),\n",
    "        \"Image\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "layout = gr.Blocks([image_block, zoomable_image_block])\n",
    "\n",
    "# Launch the Gradio Blocks interface\n",
    "layout.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f57e7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# HTML code for the zoomable image\n",
    "zoomable_image_html = \"\"\"\n",
    "<style>\n",
    ".zoom {\n",
    "  padding: 50px;\n",
    "  background-color: white;\n",
    "  transition: transform .2s;\n",
    "  width: 200px;\n",
    "  height: 200px;\n",
    "  margin: 0 auto;\n",
    "}\n",
    "\n",
    ".zoom:hover {\n",
    "  transform: scale(1.5); \n",
    "}\n",
    "</style>\n",
    "<div style='position:relative;width:50%;height:50%;', class='zoom'>\n",
    "    <img id='zoomable-image' src='https://source.unsplash.com/random' style='width:100%;height:auto;'>\n",
    "</div>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Gradio interface for displaying the zoomable image\n",
    "# iface = gr.Interface(\n",
    "#     fn=(lambda x: x),\n",
    "#     inputs=None,\n",
    "#     outputs=gr.HTML(zoomable_image_html),\n",
    "#     title=\"Zoomable Image Viewer\",\n",
    "# )\n",
    "\n",
    "# # Launch the Gradio interface\n",
    "# iface.launch()\n",
    "\n",
    "with gr.Blocks() as test:\n",
    "    gr.HTML(zoomable_image_html)\n",
    "\n",
    "test.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9a9cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoomable_image_html = \"\"\"\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<title>Zoomable Image</title>\n",
    "<style>\n",
    ".image-zoom-container {\n",
    "  overflow: hidden;\n",
    "  position: relative;\n",
    "  width: 200px; /* Adjust width and height as needed */\n",
    "  height: 200px;\n",
    "}\n",
    "\n",
    ".zoom-image {\n",
    "  display: block;\n",
    "  width: 100%;\n",
    "  transition: transform 0.3s ease;\n",
    "}\n",
    "\n",
    ".zoom-image:hover {\n",
    "  transform: scale(1.2); /* Adjust the zoom level as needed */\n",
    "  transition: transform 0.3s ease;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<div style='position:relative;width:50%;height:50%;'class=\"image-zoom-container\">\n",
    "  <img src='https://source.unsplash.com/random' class=\"zoom-image\" alt=\"Zoomable Image\">\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "document.querySelector('.image-zoom-container').addEventListener('mousemove', function(e) {\n",
    "  const boundingRect = this.getBoundingClientRect();\n",
    "  const offsetX = e.clientX - boundingRect.left;\n",
    "  const offsetY = e.clientY - boundingRect.top;\n",
    "  const image = this.querySelector('.zoom-image');\n",
    "  const imageWidth = image.offsetWidth;\n",
    "  const imageHeight = image.offsetHeight;\n",
    "  const mouseXPercent = offsetX / boundingRect.width;\n",
    "  const mouseYPercent = offsetY / boundingRect.height;\n",
    "  const scaleAmount = 1.2; // Adjust the scale amount as needed\n",
    "  const translateX = (imageWidth * scaleAmount - imageWidth) * mouseXPercent;\n",
    "  const translateY = (imageHeight * scaleAmount - imageHeight) * mouseYPercent;\n",
    "  image.style.transformOrigin = `${mouseXPercent * 100}% ${mouseYPercent * 100}%`;\n",
    "  image.style.transform = `translate(-${translateX}px, -${translateY}px) scale(${scaleAmount})`;\n",
    "});\n",
    "</script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Gradio interface for displaying the zoomable image\n",
    "# iface = gr.Interface(\n",
    "#     fn=(lambda x: x),\n",
    "#     inputs=None,\n",
    "#     outputs=gr.HTML(zoomable_image_html),\n",
    "#     title=\"Zoomable Image Viewer\",\n",
    "# )\n",
    "\n",
    "# # Launch the Gradio interface\n",
    "# iface.launch()\n",
    "\n",
    "with gr.Blocks() as test:\n",
    "    gr.HTML(zoomable_image_html)\n",
    "\n",
    "test.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a274166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
